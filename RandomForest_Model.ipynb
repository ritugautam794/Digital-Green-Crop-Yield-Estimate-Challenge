{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Rs7JXLc8Q97F"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\pythonsetup\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sJOjQeDERUXF"
   },
   "outputs": [],
   "source": [
    "# Load files\n",
    "data_path = ''\n",
    "train = pd.read_csv(data_path + 'Train.csv')\n",
    "test = pd.read_csv(data_path + 'Test.csv')\n",
    "sample_submission = pd.read_csv(data_path + 'SampleSubmission.csv')\n",
    "var_desc = pd.read_csv(data_path + 'VariableDescription.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "id": "-DYw7CKsR0cZ",
    "outputId": "eb1c9560-083c-4348-a0a2-13bcf0162445"
   },
   "outputs": [],
   "source": [
    "# Preview files\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "id": "r0unIVyIR0Zq",
    "outputId": "e866b1f5-655f-4116-bb01-bc9a239ba86a"
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "M1cox4McUNC7",
    "outputId": "2e2753c9-2877-4354-a34d-d4e1e4540dbf"
   },
   "outputs": [],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Disturbutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in train.columns:\n",
    "    try:\n",
    "        sns.histplot(data=train, x=column, kde=True)\n",
    "        plt.title(f'Univariate Distribution of {column}')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for column {column}: {e}\")\n",
    "        continue  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HANDLING MISSING VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                       0\n",
       "District                                 0\n",
       "Block                                    0\n",
       "CultLand                                 0\n",
       "CropCultLand                             0\n",
       "LandPreparationMethod                    0\n",
       "CropTillageDate                          0\n",
       "CropTillageDepth                         0\n",
       "CropEstMethod                            0\n",
       "RcNursEstDate                           83\n",
       "SeedingSowingTransplanting               0\n",
       "SeedlingsPerPit                          0\n",
       "NursDetFactor                          289\n",
       "TransDetFactor                         289\n",
       "TransplantingIrrigationHours             0\n",
       "TransplantingIrrigationSource          115\n",
       "TransplantingIrrigationPowerSource     503\n",
       "TransIrriCost                            0\n",
       "StandingWater                            0\n",
       "OrgFertilizers                        1335\n",
       "Ganaura                                  0\n",
       "CropOrgFYM                               0\n",
       "PCropSolidOrgFertAppMethod            1337\n",
       "NoFertilizerAppln                        0\n",
       "CropbasalFerts                         188\n",
       "BasalDAP                                 0\n",
       "BasalUrea                                0\n",
       "MineralFertAppMethod                     0\n",
       "FirstTopDressFert                      485\n",
       "1tdUrea                                  0\n",
       "1appDaysUrea                             0\n",
       "2tdUrea                                  0\n",
       "2appDaysUrea                             0\n",
       "MineralFertAppMethod.1                 481\n",
       "Harv_method                              0\n",
       "Harv_date                                0\n",
       "Harv_hand_rent                           0\n",
       "Threshing_date                           0\n",
       "Threshing_method                         0\n",
       "Residue_length                           0\n",
       "Residue_perc                             0\n",
       "Stubble_use                              0\n",
       "Acre                                     0\n",
       "Yield                                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_cols = train.select_dtypes(include=['number'])\n",
    "train[numerical_cols.columns] = train[numerical_cols.columns].fillna(train[numerical_cols.columns].median())\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()\n",
    "train['MineralFertAppMethod2'] = train['MineralFertAppMethod.1']\n",
    "train = train.drop(columns='MineralFertAppMethod.1') \n",
    "\n",
    "mode_value = train['MineralFertAppMethod2'].mode()[0]\n",
    "train['MineralFertAppMethod2'].fillna(mode_value, inplace=True)\n",
    "\n",
    "mode_value = train['PCropSolidOrgFertAppMethod'].mode()[0]\n",
    "train['PCropSolidOrgFertAppMethod'].fillna(mode_value, inplace=True)\n",
    "\n",
    "mode_value = train['TransplantingIrrigationSource'].mode()[0]\n",
    "train['TransplantingIrrigationSource'].fillna(mode_value, inplace=True)\n",
    "\n",
    "mode_value = train['TransplantingIrrigationPowerSource'].mode()[0]\n",
    "train['TransplantingIrrigationPowerSource'].fillna(mode_value, inplace=True)\n",
    "\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                       0\n",
       "District                                 0\n",
       "Block                                    0\n",
       "CultLand                                 0\n",
       "CropCultLand                             0\n",
       "LandPreparationMethod                    0\n",
       "CropTillageDate                          0\n",
       "CropTillageDepth                         0\n",
       "CropEstMethod                            0\n",
       "RcNursEstDate                           83\n",
       "SeedingSowingTransplanting               0\n",
       "SeedlingsPerPit                          0\n",
       "NursDetFactor                          289\n",
       "TransDetFactor                         289\n",
       "TransplantingIrrigationHours             0\n",
       "TransplantingIrrigationSource            0\n",
       "TransplantingIrrigationPowerSource       0\n",
       "TransIrriCost                            0\n",
       "StandingWater                            0\n",
       "OrgFertilizers                        1335\n",
       "Ganaura                                  0\n",
       "CropOrgFYM                               0\n",
       "PCropSolidOrgFertAppMethod               0\n",
       "NoFertilizerAppln                        0\n",
       "CropbasalFerts                         188\n",
       "BasalDAP                                 0\n",
       "BasalUrea                                0\n",
       "MineralFertAppMethod                     0\n",
       "FirstTopDressFert                      485\n",
       "1tdUrea                                  0\n",
       "1appDaysUrea                             0\n",
       "2tdUrea                                  0\n",
       "2appDaysUrea                             0\n",
       "Harv_method                              0\n",
       "Harv_date                                0\n",
       "Harv_hand_rent                           0\n",
       "Threshing_date                           0\n",
       "Threshing_method                         0\n",
       "Residue_length                           0\n",
       "Residue_perc                             0\n",
       "Stubble_use                              0\n",
       "Acre                                     0\n",
       "Yield                                    0\n",
       "MineralFertAppMethod2                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                     0\n",
       "District                               0\n",
       "Block                                  0\n",
       "CultLand                               0\n",
       "CropCultLand                           0\n",
       "LandPreparationMethod                  0\n",
       "CropTillageDate                        0\n",
       "CropTillageDepth                       0\n",
       "CropEstMethod                          0\n",
       "RcNursEstDate                         83\n",
       "SeedingSowingTransplanting             0\n",
       "SeedlingsPerPit                        0\n",
       "NursDetFactor                          0\n",
       "TransDetFactor                         0\n",
       "TransplantingIrrigationHours           0\n",
       "TransplantingIrrigationSource          0\n",
       "TransplantingIrrigationPowerSource     0\n",
       "TransIrriCost                          0\n",
       "StandingWater                          0\n",
       "OrgFertilizers                         0\n",
       "Ganaura                                0\n",
       "CropOrgFYM                             0\n",
       "PCropSolidOrgFertAppMethod             0\n",
       "NoFertilizerAppln                      0\n",
       "CropbasalFerts                         0\n",
       "BasalDAP                               0\n",
       "BasalUrea                              0\n",
       "MineralFertAppMethod                   0\n",
       "FirstTopDressFert                      0\n",
       "1tdUrea                                0\n",
       "1appDaysUrea                           0\n",
       "2tdUrea                                0\n",
       "2appDaysUrea                           0\n",
       "Harv_method                            0\n",
       "Harv_date                              0\n",
       "Harv_hand_rent                         0\n",
       "Threshing_date                         0\n",
       "Threshing_method                       0\n",
       "Residue_length                         0\n",
       "Residue_perc                           0\n",
       "Stubble_use                            0\n",
       "Acre                                   0\n",
       "Yield                                  0\n",
       "MineralFertAppMethod2                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_with_missing = ['NursDetFactor', 'TransDetFactor', 'OrgFertilizers', 'CropbasalFerts', 'FirstTopDressFert']\n",
    "\n",
    "# Iterate through each column and impute missing values with the mode\n",
    "for column in columns_with_missing:\n",
    "    mode_value = train[column].mode()[0]  # Calculate the mode\n",
    "    train[column].fillna(mode_value, inplace=True)\n",
    "    \n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have a DataFrame named 'df' with five date columns: 'Date1', 'Date2', 'Date3', 'Date4', 'Date5'\n",
    "\n",
    "# Convert the date columns to datetime format (if not already done)\n",
    "date_columns = ['CropTillageDate', 'RcNursEstDate', 'SeedingSowingTransplanting', 'Harv_date', 'Threshing_date']\n",
    "for col in date_columns:\n",
    "    train[col] = pd.to_datetime(train[col])\n",
    "\n",
    "# Calculate the time differences between the date columns\n",
    "for i in range(len(date_columns)):\n",
    "    for j in range(i + 1, len(date_columns)):\n",
    "        time_diff = (train[date_columns[j]] - train[date_columns[i]]).dt.days\n",
    "        print(f\"Time difference between {date_columns[i]} and {date_columns[j]}:\")\n",
    "        print(time_diff.describe())\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Visualize the relationships between the date columns\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(len(date_columns)):\n",
    "    for j in range(i + 1, len(date_columns)):\n",
    "        plt.scatter(train[date_columns[i]], train[date_columns[j]], label=f\"{date_columns[i]} vs. {date_columns[j]}\")\n",
    "\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Date\")\n",
    "plt.title(\"Relationships between Date Columns\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_columns = ['CropTillageDate', 'RcNursEstDate', 'Harv_date', 'Threshing_date']\n",
    "for col in date_columns:\n",
    "    train[col] = pd.to_datetime(train[col])\n",
    "\n",
    "# Create line plots for the four date columns\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for col in date_columns:\n",
    "    plt.plot(train[col], label=col)\n",
    "\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Date Columns Over Time\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                    0\n",
       "District                              0\n",
       "Block                                 0\n",
       "CultLand                              0\n",
       "CropCultLand                          0\n",
       "LandPreparationMethod                 0\n",
       "CropTillageDate                       0\n",
       "CropTillageDepth                      0\n",
       "CropEstMethod                         0\n",
       "RcNursEstDate                         0\n",
       "SeedingSowingTransplanting            0\n",
       "SeedlingsPerPit                       0\n",
       "NursDetFactor                         0\n",
       "TransDetFactor                        0\n",
       "TransplantingIrrigationHours          0\n",
       "TransplantingIrrigationSource         0\n",
       "TransplantingIrrigationPowerSource    0\n",
       "TransIrriCost                         0\n",
       "StandingWater                         0\n",
       "OrgFertilizers                        0\n",
       "Ganaura                               0\n",
       "CropOrgFYM                            0\n",
       "PCropSolidOrgFertAppMethod            0\n",
       "NoFertilizerAppln                     0\n",
       "CropbasalFerts                        0\n",
       "BasalDAP                              0\n",
       "BasalUrea                             0\n",
       "MineralFertAppMethod                  0\n",
       "FirstTopDressFert                     0\n",
       "1tdUrea                               0\n",
       "1appDaysUrea                          0\n",
       "2tdUrea                               0\n",
       "2appDaysUrea                          0\n",
       "Harv_method                           0\n",
       "Harv_date                             0\n",
       "Harv_hand_rent                        0\n",
       "Threshing_date                        0\n",
       "Threshing_method                      0\n",
       "Residue_length                        0\n",
       "Residue_perc                          0\n",
       "Stubble_use                           0\n",
       "Acre                                  0\n",
       "Yield                                 0\n",
       "MineralFertAppMethod2                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['CropTillageDate'] = pd.to_datetime(train['CropTillageDate'])\n",
    "\n",
    "# Create a mask to identify missing values in 'RcNursEstDate'\n",
    "missing_mask = pd.isnull(train['RcNursEstDate'])\n",
    "\n",
    "# Subtract 15 days from 'CropTillageDate' only for missing values in 'RcNursEstDate'\n",
    "train.loc[missing_mask, 'RcNursEstDate'] = train.loc[missing_mask, 'CropTillageDate'] - pd.to_timedelta(15, unit='D')\n",
    "\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                            0\n",
       "Block                         0\n",
       "CultLand                      0\n",
       "CropCultLand                  0\n",
       "LandPreparationMethod         0\n",
       "                             ..\n",
       "Harv_method_machine           0\n",
       "Threshing_method_hand         0\n",
       "Threshing_method_machine      0\n",
       "Stubble_use_burned            0\n",
       "Stubble_use_plowed_in_soil    0\n",
       "Length: 67, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.get_dummies(train, columns=[\"District\", \"CropEstMethod\", \"TransplantingIrrigationSource\"], prefix=[\"District\", \"CropEstMethod\", \"TransplantingIrrigationSource\"])\n",
    "\n",
    "\n",
    "additional_categorical_columns = [\"TransplantingIrrigationPowerSource\", \"PCropSolidOrgFertAppMethod\", \"MineralFertAppMethod\", \"MineralFertAppMethod2\", \"Harv_method\", \"Threshing_method\", \"Stubble_use\"]\n",
    "\n",
    "train = pd.get_dummies(train, columns=additional_categorical_columns, prefix=additional_categorical_columns)\n",
    "train.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, columns=[\"Block\"], prefix=[\"Block\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\pythonsetup\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-7c8574edac2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m# Make predictions on the test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_knn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;31m# Evaluate the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\pythonsetup\\lib\\site-packages\\sklearn\\neighbors\\_regression.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[1;31m# In that case, we do not need the distances to perform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[1;31m# the weighting so we do not compute them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m             \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m             \u001b[0mneigh_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\pythonsetup\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    822\u001b[0m         )\n\u001b[0;32m    823\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0muse_pairwise_distances_reductions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 824\u001b[1;33m             results = ArgKmin.compute(\n\u001b[0m\u001b[0;32m    825\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    826\u001b[0m                 \u001b[0mY\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\pythonsetup\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\u001b[0m in \u001b[0;36mcompute\u001b[1;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[0m\n\u001b[0;32m    275\u001b[0m         \"\"\"\n\u001b[0;32m    276\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m             return ArgKmin64.compute(\n\u001b[0m\u001b[0;32m    278\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m                 \u001b[0mY\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\u001b[0m in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\pythonsetup\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36mthreadpool_limits\u001b[1;34m(limits, user_api)\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcontroller\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlimits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muser_api\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mthreadpoolctl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreadpool_limits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlimits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muser_api\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\pythonsetup\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, limits, user_api)\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlimits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_threadpool_limits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\pythonsetup\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m_set_threadpool_limits\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         modules = _ThreadpoolInfo(prefixes=self._prefixes,\n\u001b[0m\u001b[0;32m    269\u001b[0m                                   user_api=self._user_api)\n\u001b[0;32m    270\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\pythonsetup\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, user_api, prefixes, modules)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_modules\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_if_incompatible_openmp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\pythonsetup\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m_load_modules\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    371\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_modules_with_dyld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"win32\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 373\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_modules_with_enum_process_module_ex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    374\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_modules_with_dl_iterate_phdr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\pythonsetup\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m_find_modules_with_enum_process_module_ex\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m                 \u001b[1;31m# Store the module if it is supported and selected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 485\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_module_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    486\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mkernel_32\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCloseHandle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_process\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\pythonsetup\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m_make_module_from_path\u001b[1;34m(self, filepath)\u001b[0m\n\u001b[0;32m    513\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprefixes\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0muser_api\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m                 \u001b[0mmodule_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodule_class\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m                 \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minternal_api\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\pythonsetup\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath, prefix, user_api, internal_api)\u001b[0m\n\u001b[0;32m    604\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal_api\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minternal_api\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dynlib\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_RTLD_NOLOAD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    607\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_threads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_num_threads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_extra_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\pythonsetup\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36mget_version\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    644\u001b[0m                              lambda: None)\n\u001b[0;32m    645\u001b[0m         \u001b[0mget_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"OpenBLAS\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = train.drop(['ID', 'Yield'], axis = 1)\n",
    "X =X.select_dtypes(include=np.number)\n",
    "y = train.Yield\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features (recommended for KNN)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],  # Adjust the number of neighbors\n",
    "    'weights': ['uniform', 'distance'],  # Adjust the weight function\n",
    "    'p': [1, 2]  # 1 for Manhattan distance, 2 for Euclidean distance\n",
    "}\n",
    "\n",
    "# Create the KNN regressor model\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# Define the scoring metric (e.g., mean squared error)\n",
    "scoring = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring=scoring, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Create a KNN model with the best hyperparameters\n",
    "best_knn = KNeighborsRegressor(**best_params)\n",
    "\n",
    "# Fit the model on the training data\n",
    "best_knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = best_knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Best KNN model's RMSE: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372.8991448298269"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "X = train.drop(['ID', 'Yield'], axis = 1)\n",
    "#X =X.select_dtypes(include=np.number)\n",
    "y = train.Yield\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1234)\n",
    "\n",
    "# Instantiate model\n",
    "model = RandomForestRegressor(random_state = 1234)\n",
    "\n",
    "# Fit model\n",
    "model.fit(X_train.fillna(0), y_train)\n",
    "\n",
    "# Make predictions\n",
    "preds = model.predict(X_test.fillna(0))\n",
    "\n",
    "# Measure model performance\n",
    "mean_squared_error(y_test, preds, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the Zindi test set\n",
    "test_df = test[X.columns]\n",
    "preds = model.predict(test_df.fillna(0))\n",
    "\n",
    "# Create submisiion file to be uploaded to Zindi for scoring\n",
    "sub = pd.DataFrame({'ID': test.ID, 'Yield': preds})\n",
    "sub.to_csv('BenchmarkSubmission.csv', index = False)\n",
    "\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"NoFertilizerAppln_per_Acre\"] = train[\"NoFertilizerAppln\"] / train[\"Acre\"]\n",
    "train[\"StandingWater_per_Acre\"] = train[\"StandingWater\"] / train[\"Acre\"]\n",
    "train['CropCultLand_Percentage'] = (train['CropCultLand'] / train['CultLand']) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train[\"RcNursEstDate\"] = pd.to_datetime(train[\"RcNursEstDate\"])\n",
    "train[\"CropTillageDate\"] = pd.to_datetime(train[\"CropTillageDate\"])\n",
    "train[\"Harv_date\"] = pd.to_datetime(train[\"Harv_date\"])\n",
    "train[\"SeedingSowingTransplanting\"] = pd.to_datetime(train[\"SeedingSowingTransplanting\"])\n",
    "\n",
    "train[\"CropTillage_to_RcNursEstDuration\"] = (train[\"RcNursEstDate\"] - train[\"CropTillageDate\"]).dt.days\n",
    "train[\"RcNursEst_to_HarvestDuration\"] = (train[\"Harv_date\"] - train[\"RcNursEstDate\"]).dt.days\n",
    "train[\"SeedlingTransplanting_to_CropTillageDate\"] = (train[\"SeedingSowingTransplanting\"] - train[\"CropTillageDate\"]).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For test dataset\n",
    "test[\"NoFertilizerAppln_per_Acre\"] = test[\"NoFertilizerAppln\"] / test[\"Acre\"]\n",
    "test[\"StandingWater_per_Acre\"] = test[\"StandingWater\"] / test[\"Acre\"]\n",
    "#test[\"Acre_Yield\"] = test[\"Acre\"] * test[\"Yield\"]\n",
    "test['CropCultLand_Percentage'] = (test['CropCultLand'] / test['CultLand']) * 100\n",
    "\n",
    "# Convert date columns to datetime format\n",
    "test[\"RcNursEstDate\"] = pd.to_datetime(test[\"RcNursEstDate\"])\n",
    "test[\"CropTillageDate\"] = pd.to_datetime(test[\"CropTillageDate\"])\n",
    "test[\"Harv_date\"] = pd.to_datetime(test[\"Harv_date\"])\n",
    "\n",
    "# Calculate date differences\n",
    "test[\"CropTillage_to_RcNursEstDuration\"] = (test[\"RcNursEstDate\"] - test[\"CropTillageDate\"]).dt.days\n",
    "test[\"RcNursEst_to_HarvestDuration\"] = (test[\"Harv_date\"] - test[\"RcNursEstDate\"]).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, columns=[\"District\", \"CropEstMethod\", \"TransplantingIrrigationSource\"], prefix=[\"District\", \"CropEstMethod\", \"TransplantingIrrigationSource\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "additional_categorical_columns = [\"TransplantingIrrigationPowerSource\", \"PCropSolidOrgFertAppMethod\", \"MineralFertAppMethod\", \"MineralFertAppMethod2\", \"Harv_method\", \"Threshing_method\", \"Stubble_use\"]\n",
    "\n",
    "train = pd.get_dummies(train, columns=additional_categorical_columns, prefix=additional_categorical_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for training and local testing\n",
    "\n",
    "X = train.drop(['ID', 'Yield'], axis = 1)\n",
    "X =X.select_dtypes(include=np.number)\n",
    "y = train.Yield\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1234)\n",
    "\n",
    "# Instantiate model\n",
    "model = RandomForestRegressor(random_state = 1234)\n",
    "\n",
    "# Fit model\n",
    "model.fit(X_train.fillna(0), y_train)\n",
    "\n",
    "# Make predictions\n",
    "preds = model.predict(X_test.fillna(0))\n",
    "\n",
    "# Measure model performance\n",
    "mean_squared_error(y_test, preds, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the Zindi test set\n",
    "test_df = test[X.columns]\n",
    "preds = model.predict(test_df.fillna(0))\n",
    "\n",
    "# Create submisiion file to be uploaded to Zindi for scoring\n",
    "sub = pd.DataFrame({'ID': test.ID, 'Yield': preds})\n",
    "sub.to_csv('BenchmarkSubmission.csv', index = False)\n",
    "\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "#from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = train.drop(['ID', 'Yield'], axis = 1)\n",
    "X =X.select_dtypes(include=np.number)\n",
    "y = train.Yield\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "decision_tree_model = DecisionTreeClassifier()\n",
    "decision_tree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_model = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), n_estimators=50)\n",
    "adaboost_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model = XGBClassifier()\n",
    "xgboost_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm_model = LGBMClassifier()\n",
    "lightgbm_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [decision_tree_model, adaboost_model, xgboost_model, lightgbm_model, knn_model]\n",
    "model_names = ['Decision Tree', 'AdaBoost', 'XGBoost', 'LightGBM', 'KNN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "#from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1234)\n",
    "\n",
    "# Define a list of models to train and evaluate\n",
    "models = [\n",
    "    (\"Random Forest\", RandomForestRegressor(random_state=1234)),\n",
    "    (\"Decision Tree\", DecisionTreeRegressor(random_state=1234)),\n",
    "    (\"Gradient Boosting\", GradientBoostingRegressor(random_state=1234)),\n",
    "   # (\"XGBoost\", XGBRegressor(random_state=1234)),\n",
    "    (\"AdaBoost\", AdaBoostRegressor(random_state=1234)),\n",
    "    (\"LightGBM\", LGBMRegressor(random_state=1234)),\n",
    "    (\"K-Nearest Neighbors\", KNeighborsRegressor(n_neighbors=5)),\n",
    "\n",
    "   \n",
    "]\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models:\n",
    "    # Fit the model\n",
    "    model.fit(X_train.fillna(0), y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    preds = model.predict(X_test.fillna(0))\n",
    "\n",
    "    # Measure model performance\n",
    "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "    print(f\"{model_name} - Root Mean Squared Error: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "#from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Assuming you have your data in X and y\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1234)\n",
    "\n",
    "# Define a list of models to train and evaluate\n",
    "models = [\n",
    "    (\"Random Forest\", RandomForestRegressor(random_state=1234)),\n",
    "    (\"Decision Tree\", DecisionTreeRegressor(random_state=1234)),\n",
    "    (\"Gradient Boosting\", GradientBoostingRegressor(random_state=1234)),\n",
    "    #(\"XGBoost\", XGBRegressor(random_state=1234)),\n",
    "    (\"AdaBoost\", AdaBoostRegressor(random_state=1234)),\n",
    "    (\"LightGBM\", LGBMRegressor(random_state=1234)),\n",
    "   # (\"K-Nearest Neighbors\", KNeighborsRegressor(n_neighbors=5)),\n",
    "]\n",
    "\n",
    "# Define hyperparameters for tuning\n",
    "param_grid = {\n",
    "   \"Random Forest\": {\n",
    "        \"n_estimators\": [200, 300, 400, 500],\n",
    "        \"max_depth\": [None, 10, 20, 30],\n",
    "        \"max_features\": ['auto', 'sqrt', 'log2', None, 0.5, 0.7],  \n",
    "        \"max_samples\": [0.5, 0.7, 0.9, None],  \n",
    "        \"min_samples_split\": [2, 5, 10],  \n",
    "    },\n",
    "    \"Decision Tree\": {\n",
    "        \"max_depth\": [None, 10, 20, 30],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4],\n",
    "        \"max_features\": ['auto', 'sqrt', 'log2', None],\n",
    "        \"criterion\": [\"gini\", \"entropy\"],\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "         \"max_depth\": [3, 4, 5, 6],  \n",
    "        \"max_bin\": [100, 200, 255, 300] \n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "        \"max_depth\": [3, 4, 5, 6],  \n",
    "        \"max_bin\": [100, 200, 255, 300]  \n",
    "    },\n",
    "    \"AdaBoost\": {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "         \"max_depth\": [3, 4, 5, 6],  \n",
    "        \"max_bin\": [100, 200, 255, 300],\n",
    "    },\n",
    "    \"LightGBM\": {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "        \"max_depth\": [3, 4, 5, 6],  \n",
    "        \"max_bin\": [100, 200, 255, 300], \n",
    "    },\n",
    "    \"K-Nearest Neighbors\": {\n",
    "        \"n_neighbors\": [3, 5, 7],\n",
    "    },\n",
    "}\n",
    "\n",
    "# Train and evaluate each model with hyperparameter tuning\n",
    "for model_name, model in models:\n",
    "    param_grid[model_name]\n",
    "    grid_search = GridSearchCV(model, param_grid[model_name], cv=5, scoring=\"neg_mean_squared_error\")\n",
    "    grid_search.fit(X_train.fillna(0), y_train)\n",
    "\n",
    "    # Get the best estimator from the grid search\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Make predictions\n",
    "    preds = best_model.predict(X_test.fillna(0))\n",
    "\n",
    "    # Measure model performance\n",
    "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "    print(f\"{model_name} - Root Mean Squared Error: {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_convert = ['LandPreparationMethod', 'NursDetFactor', 'TransDetFactor', \n",
    " 'OrgFertilizers' ,'CropbasalFerts','FirstTopDressFert' ]\n",
    "\n",
    "# Create dummy variables for the specified columns\n",
    "for column in columns_to_convert:\n",
    "    categories = train[column].str.split(expand=True)\n",
    "    categories = pd.get_dummies(categories, prefix=f'{column}', prefix_sep='_')\n",
    "    train = pd.concat([train, categories], axis=1)\n",
    "    #train.drop(column, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric_columns = train.drop(columns=['ID']).select_dtypes(exclude=['number']).columns\n",
    "\n",
    "# Convert non-numerical columns to categorical data type\n",
    "train[non_numeric_columns] = train[non_numeric_columns].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, columns=non_numeric_columns, prefix=non_numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_excel('output.xlsx', index=False, sheet_name='Sheet2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['ID', 'Yield'], axis=1)\n",
    "\n",
    "# Extract the target variable 'Yield'\n",
    "y = train['Yield']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1234)\n",
    "\n",
    "# Instantiate the model\n",
    "model = RandomForestRegressor(random_state=1234)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train.fillna(0), y_train)\n",
    "\n",
    "# Make predictions\n",
    "preds = model.predict(X_test.fillna(0))\n",
    "\n",
    "# Measure model performance\n",
    "rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "print(\"Root Mean Squared Error:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_convert = ['NursDetFactor']\n",
    "\n",
    "# Create dummy variables for the specified columns\n",
    "for column in columns_to_convert:\n",
    "    # Split the values in the column by spaces\n",
    "    categories = train[column].str.split(expand=True)\n",
    "\n",
    "    # Create dummy variables with NaNs (missing values) preserved\n",
    "    categories = pd.get_dummies(categories, prefix=f'{column}', prefix_sep='_', dummy_na=True)\n",
    "\n",
    "    # Concatenate the dummy variables with the original DataFrame\n",
    "    train = pd.concat([train, categories], axis=1)\n",
    "\n",
    "    # Drop the original column\n",
    "    train.drop(column, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_excel('output.xlsx', index=False, sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.histplot(data=train, x='TransplantingIrrigationSource', bins=10)  # You can adjust the number of bins as needed\n",
    "plt.xlabel('Transplanting Irrigation Source')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Transplanting Irrigation Source')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputed_loans_df = imputed_loans_df.copy()\n",
    "\n",
    "grade_mapping = {'A1': 1, 'A2': 2, 'A3': 3, 'B1': 4, 'B2': 5, 'B3': 6, 'C1': 7, 'C2': 8, 'C3': 9, 'C4': 10, 'C5': 11, 'C6': 12}\n",
    "imputed_loans_df['display_grade'] = imputed_loans_df['display_grade'].map(grade_mapping)\n",
    "\n",
    "valid_rows = imputed_loans_df.dropna(subset=['display_grade', 'debt to income ratio'])\n",
    "\n",
    "# Create X (feature) and y (target) for training the model\n",
    "X_train = valid_rows[['debt to income ratio']]\n",
    "y_train = valid_rows['display_grade']\n",
    "\n",
    "# Initialize and fit a linear regression model\n",
    "regression_model = LinearRegression()\n",
    "regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Extract rows with missing 'display_grade' values\n",
    "missing_grade_rows = imputed_loans_df[imputed_loans_df['display_grade'].isnull()]\n",
    "\n",
    "# Impute missing 'display_grade' values based on the regression model\n",
    "if not missing_grade_rows.empty:\n",
    "   missing_grade_predictions = regression_model.predict(missing_grade_rows[['debt to income ratio']])\n",
    "   missing_grade_rows['display_grade'] = missing_grade_predictions.round().astype(int)\n",
    "# Merge the imputed data back with the original dataset\n",
    "\n",
    "imputed_loans_df.update(missing_grade_rows)\n",
    "# Print the sum of null values to veri\n",
    "\n",
    "imputed_loans_df['display_grade'].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['MineralFertAppMethod2'] = train['MineralFertAppMethod.1']\n",
    "train = train.drop(columns='MineralFertAppMethod.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_convert = ['LandPreparationMethod', 'NursDetFactor', 'TransDetFactor', \n",
    ", 'OrgFertilizers' ,'CropbasalFerts','FirstTopDressFert' ]\n",
    "\n",
    "# Create dummy variables for the specified columns\n",
    "for column in columns_to_convert:\n",
    "    categories = train[column].str.split(expand=True)\n",
    "    categories = pd.get_dummies(categories, prefix=f'{column}', prefix_sep='_')\n",
    "    train = pd.concat([train, categories], axis=1)\n",
    "    train.drop(column, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = train.columns.tolist()\n",
    "\n",
    "# Print the list of all column names\n",
    "print(\"List of all column names:\")\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_missing_values = train.columns[train.isnull().all()]\n",
    "\n",
    "# Calculate the number of missing values in each of these columns\n",
    "missing_value_counts = train[columns_with_missing_values].isnull().sum()\n",
    "\n",
    "# Combine the column names and their missing value counts into a DataFrame\n",
    "missing_info = pd.DataFrame({'Column Name': columns_with_missing_values, 'Missing Values Count': missing_value_counts})\n",
    "\n",
    "# Print the columns and their missing value counts\n",
    "print(missing_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_10_columns = train.iloc[:, :25]\n",
    "df_first_10_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jZ2BE29rR0Xs",
    "outputId": "d83ae4a9-3af8-433b-a338-f18c2b7cf5be"
   },
   "outputs": [],
   "source": [
    "# Split data for training and local testing\n",
    "\n",
    "X = train.drop(['ID', 'Yield'], axis = 1)\n",
    "X =X.select_dtypes(include=np.number)\n",
    "y = train.Yield\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1234)\n",
    "\n",
    "# Instantiate model\n",
    "model = RandomForestRegressor(random_state = 1234)\n",
    "\n",
    "# Fit model\n",
    "model.fit(X_train.fillna(0), y_train)\n",
    "\n",
    "# Make predictions\n",
    "preds = model.predict(X_test.fillna(0))\n",
    "\n",
    "# Measure model performance\n",
    "mean_squared_error(y_test, preds, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "wpL7M1GWR0Vp",
    "outputId": "4ad5c2e2-dccb-4873-c09c-17d3f436c7f3"
   },
   "outputs": [],
   "source": [
    "# Make predictions on the Zindi test set\n",
    "test_df = test[X.columns]\n",
    "preds = model.predict(test_df.fillna(0))\n",
    "\n",
    "# Create submisiion file to be uploaded to Zindi for scoring\n",
    "sub = pd.DataFrame({'ID': test.ID, 'Yield': preds})\n",
    "sub.to_csv('BenchmarkSubmission.csv', index = False)\n",
    "\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
